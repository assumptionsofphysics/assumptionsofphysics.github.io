---
title: The physical meaning of h-bar
summary: Planck's constant sets the minimum spread imposed by the third law of thermodynamics
category: Thermodynamics
tags: [Quantum mechanics, Entropy]
draft: true
---

The reduced Planck's constant $$\hbar$$ immediately conjured quantum mechanics in the mind of most people who know a bit of physics. Therefore where I show that classical mechanics has a similar uncertainty principle, which also depends on $$\hbar$$, they appear perplex and wonder why does $$\hbar$$ appear. The issue is that Planck's constant is really a thermodynamic constant. The fact that appears in quantum mechanics prominently is because quantum mechanics is there to fix a major problem in statistical mechanics: the prediction of ensembles with negative entropy, which violate the third law. Once you understand this, you are on the right track to understand what Planck's constant represents... and why quantum mechanics is necessary.

First, note that Planck intoduced his constant in his effort to derive a formula that would correctly predict the thermal distribution of a black-body. That is a problem in thermodynamics/statistical mechanics. In the old quantum theory, it was speculated that the action could not take arbitrary values, but rather only integer multiples of $$h$$, which was called the "quantum of action". The idea was that trajectory in phase space existed, but they were hidden. All of this did not pan out, and old quantum theory was abandoned in favor of the new quantum theory, the one we now just call quantum theory, which talks about wavefunction and its evolution. The connection between $$h$$ and $$\hbar$$ to action and thermodynamics was less stressed, and the constant became the link between energy and frequency, momentum and wavelength.

Now, one of the results of our project is a physical and geometrical interpretation of the action principle, which allows to say exactly what the mathematical objects represent physically. We show that the action is the line integral of the vector potential of the flow of states. What matters here is that it is a potential, much like the potential of the magnetic field. Therefore the value of the action itself is not physically meaningful, in the same way that the value of the potential at one point is not physically meaningful. Therefore saying talking about "quantum of action" does not make much sense physically. However, $$h$$ can still be understood as an area in phase space. That has physical meaning because areas in phase space counts possible configurations for a degree of freedom (DOF). Count of states is deeply connected to entropy, though the actual connection between entropy and statistical mechanics was developed a bit later, late 1950s. Moreover, the third law establishes that the entropy cannot be less than zero.

So we have three things:
1. areas in phase space cannot be smaller than $$h$$
2. entropy is a function of areas in phase space
3. entropy cannot be smaller than zero
This is not an analogy: we can make this connection precise.

Given a probability distribution $$\rho$$ over position and momentum, the entropy is given by $$-\int \rho \log \rho \, dx dp$$. If the distribution is uniform, the expression reduces to $$\log W$$ where $$W$$ is the area of the region that supports the uniform distribution. Now, if you do some dimensional checking, something that somehow theoretical physics has stopped doing, we note that $$\log W$$ does not make sense: $$W$$ had dimensions of a probability density over phase space, and therefore has units of probability over phase space areas. We need to define the unit of phase space. How do we do it? Let us define $$h$$ as the area of phase space that corresponds to a uniform distribution with zero entropy. The above formula, then, is amended to $$\log W/h$$, a logarithm of a pure number, and if $$W=h$$, then the entropy is zero.

If the entropy of a uniform distribution depends on the area, then it is clear that we cannot have distributions of smaller size. Note that we are not at all saying that areas must come in integer multiples of $$h$$. Simply, that there is a minimum. If you shrink the area in position, it will have to increase in momentum. Yet, this is not the smallest uncertainty we can have. If we keep the entropy constant, the distribution that minizes the uncertainty is the Gaussian. For a gaussian distribution, the product of the standard deviations become $$\sigma_x \sigma_p = \frac{h}{2\pi e} = \frac{h}{e}$$. This is the minimum uncertainty possible. For a generic distribution, then, we must have $$\sigma_x \sigma_p \leq \frac{h}{e}$$.

Note that there is no quantum of action, no quantization of energy, just the third law and its lower bound on entropy. Note how go from $$h$$ to $$\hbar$$ naturally as the uncertainty for a Gaussian adds the factor of $$2\pi$$. Or $$\tau$$. Also note that $$e$$ is slightly bigger than $$2$$, so the classical uncertainty principle has a slightly different lower bound.

In the following diagram we plot the uncertainty of guassian states of both classical and quantum mechanics as a function of uncertainty in units of $$\hbar$$.
<p align="center">
  <img alt="Uncertainty of Guassian distribtuions" src="/assets/images/essays/GaussianUncertainty.png" />
</p>
Note that for even a couple of units of uncertainty, the entropy graph becomes basically indistinguishable. At zero entropy, the classical uncertainty is as $$\frac{h}{e}$$ while the quantum one is at $$\frac{h}{2}$$. This is a quantitative difference. Then quantum mechanics stops, as states with lower uncertainty do not exists, while classical mechanics keeps going, violating the third law. So, why is it that quantum mechanics has a higher lower bound for uncertainty? Note that the lowest uncertainty is obtained when the distributions for position and momentum are independent. This is the correction that new quantum theory with respect to the old quantum theory: in a pure gaussian states position and momentum are not independent. The ability to talk about position and momentum at the same time is exactly the ability to fix one without fixing the other. We would need ensembles at negative entropy to be able to define their value at greater precision, which is not possible.

The reason why the world is not classical is that classical mechanics does not make sense thermodynamically. The third law of thermodynamics is the only thing we need to impose to derive the existence of $$h$$ and an uncertainty principle in terms of $$\hbar$$. This is the road to actually understand quantum mechanics.
